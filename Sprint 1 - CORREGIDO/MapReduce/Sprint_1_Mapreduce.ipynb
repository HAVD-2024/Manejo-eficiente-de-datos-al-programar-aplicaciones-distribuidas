{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# JVM needs to be re-installed\n",
        "apt-get update > /dev/null\n",
        "apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Descargar Hadoop\n",
        "wget -q https://downloads.apache.org/hadoop/common/hadoop-3.3.5/hadoop-3.3.5.tar.gz\n",
        "tar -xzf hadoop-3.3.5.tar.gz\n",
        "mv hadoop-3.3.5/ /usr/local/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrJ-_vx8MZuX",
        "outputId": "86b8ecf5-a104-4f2e-c3b5-f305577c97fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "HADOOP_VERSION = \"3.3.5\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "os.environ[\"HADOOP_HOME\"] = f\"/usr/local/hadoop-{HADOOP_VERSION}/\"\n",
        "\n",
        "# Agrega el Hadoop BIN al PATH\n",
        "current_path = os.getenv('PATH')\n",
        "new_path = current_path + f\":/usr/local/hadoop-{HADOOP_VERSION}/bin/\"\n",
        "os.environ[\"PATH\"] = new_path\n",
        "\n",
        "# Verificar si PATH contiene Hadoop\n",
        "!echo $PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMx8SE2mMkwq",
        "outputId": "4ed3b4ba-fe4b-4a37-aab9-6befc789c83a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.5/bin/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hadoop version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70t10zjGMnGP",
        "outputId": "505b70c0-130e-4549-a642-3c83d6de2bb9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hadoop 3.3.5\n",
            "Source code repository https://github.com/apache/hadoop.git -r 706d88266abcee09ed78fbaa0ad5f74d818ab0e9\n",
            "Compiled by stevel on 2023-03-15T15:56Z\n",
            "Compiled with protoc 3.7.1\n",
            "From source with checksum 6bbd9afcf4838a0eb12a5f189e9bd7\n",
            "This command was run using /usr/local/hadoop-3.3.5/share/hadoop/common/hadoop-common-3.3.5.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /usr/local/hadoop/etc/hadoop/"
      ],
      "metadata": {
        "id": "gq8f8gnUMnkh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://downloads.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz\n",
        "!tar xzf apache-hive-3.1.3-bin.tar.gz"
      ],
      "metadata": {
        "id": "9wMjTpIXMpoR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HIVE_HOME\"] = \"/content/apache-hive-3.1.3-bin\"\n",
        "\n",
        "!echo $HIVE_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjapSKW8MsFW",
        "outputId": "be2adab5-cb7b-4242-ce69-c32d0607cd08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-hive-3.1.3-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_path = os.getenv('PATH')\n",
        "new_path = current_path+':/content/apache-hive-3.1.3-bin/bin'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClOn0wDOMukB",
        "outputId": "d4de5e21-9038-41ff-c15f-67943b753977"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/hadoop-3.3.5/bin/:/content/apache-hive-3.1.3-bin/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $JAVA_HOME\n",
        "!echo $HADOOP_HOME\n",
        "!echo $HIVE_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91gv1OGwMvw4",
        "outputId": "156657cd-8229-4d01-e398-4069b7938aa3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "/usr/local/hadoop-3.3.5/\n",
            "/content/apache-hive-3.1.3-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *.tar.gz"
      ],
      "metadata": {
        "id": "qTZNiNnJMxX4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hdfs dfs -mkdir /tmp\n",
        "!hdfs dfs -chmod g+w /tmp\n",
        "\n",
        "!hdfs dfs -mkdir -p /content/warehouse\n",
        "!hdfs dfs -chmod g+w /content/warehouse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4iOjKuvMzJo",
        "outputId": "315f0876-b35f-4181-f184-0ac6b3503c54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: `/tmp': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $HADOOP_HOME/share/hadoop/common/lib/*slf4j*\n",
        "!ls $HIVE_HOME/lib/*slf4j*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGcDa6pSM1dP",
        "outputId": "2e2eb796-140a-4636-ea7f-1b4c98fdee9e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.5//share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar\n",
            "/usr/local/hadoop-3.3.5//share/hadoop/common/lib/slf4j-api-1.7.36.jar\n",
            "/usr/local/hadoop-3.3.5//share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar\n",
            "/content/apache-hive-3.1.3-bin/lib/log4j-slf4j-impl-2.17.1.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/apache-hive-3.1.3-bin/lib/log4j-slf4j-impl-2.17.1.jar ./"
      ],
      "metadata": {
        "id": "xoOjL0QuM121"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $HIVE_HOME/lib/gu*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwtuEskgM4w_",
        "outputId": "7b4a8599-39ca-4795-ee46-c6784225f44b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apache-hive-3.1.3-bin/lib/guava-19.0.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $HADOOP_HOME/share/hadoop/hdfs/lib/gu*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU3fF2vLM6OH",
        "outputId": "ea930238-97e6-4ea3-9fc3-4b31a884d05b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.5//share/hadoop/hdfs/lib/guava-27.0-jre.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv $HIVE_HOME/lib/guava-19.0.jar ./\n",
        "!cp $HADOOP_HOME/share/hadoop/hdfs/lib/guava-27.0-jre.jar $HIVE_HOME/lib/"
      ],
      "metadata": {
        "id": "NwhS1WwiM7h_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea un directorio en el sistema de archivos distribuido de Hadoop (HDFS)\n",
        "# La opción '-p' asegura que se creen todos los directorios padres necesarios\n",
        "# En este caso, el directorio '/data/' se creará si no existe ya\n",
        "!hadoop fs -mkdir -p /data/"
      ],
      "metadata": {
        "id": "MDZtRiajM9mp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar Hadoop versión 3.3.1\n",
        "!wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz\n",
        "\n",
        "# Extraer el archivo descargado\n",
        "!tar -xzf hadoop-3.3.1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJU3Og8kPHls",
        "outputId": "56e18c17-7c11-4f40-9230-f03f81fecf16"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-16 20:37:42--  https://archive.apache.org/dist/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 605187279 (577M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.1.tar.gz’\n",
            "\n",
            "hadoop-3.3.1.tar.gz 100%[===================>] 577.15M  17.3MB/s    in 34s     \n",
            "\n",
            "2024-09-16 20:38:17 (16.7 MB/s) - ‘hadoop-3.3.1.tar.gz’ saved [605187279/605187279]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP8wanbLPRAY",
        "outputId": "7a91fdd3-bb65-412c-bd80-ab18f416ba01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar: Permission denied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer el archivo tar.gz\n",
        "!tar -xzf hadoop-3.3.1.tar.gz"
      ],
      "metadata": {
        "id": "LcvKiZM5RaPQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cantidad total de vuelos que existieron en cada día del mes. Denomina al maper como maper_1.py."
      ],
      "metadata": {
        "id": "aw6vs9U9kNXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/mapper_1.py\n",
        "import sys\n",
        "\n",
        "def main():\n",
        "    \"\"\"Función principal del mapper que procesa entradas de vuelos.\"\"\"\n",
        "    for line in sys.stdin:\n",
        "        # Dividir la línea por comas\n",
        "        fields = line.strip().split(',')\n",
        "\n",
        "        # Ignorar la línea de encabezado\n",
        "        if fields[0] == 'Year':\n",
        "            continue\n",
        "\n",
        "        # Extraer el día del mes\n",
        "        day_of_month = fields[3]  # Columna \"DayofMonth\"\n",
        "\n",
        "        # Emitir el día del mes con un conteo de 1\n",
        "        print(f\"{day_of_month}\\t1\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flbfvH1rRkKp",
        "outputId": "cafc58a9-91b7-4af1-e236-26645cdf1a3c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/mapper_1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cantidad total de vuelos que existieron en cada día del mes. Denomina al reducer como reducer_1.py."
      ],
      "metadata": {
        "id": "8VYKEmMfka0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/reducer_1.py\n",
        "import sys\n",
        "\n",
        "def main():\n",
        "    \"\"\"Función principal del reducer que suma el conteo de vuelos por día.\"\"\"\n",
        "    current_day = None\n",
        "    total_flights = 0\n",
        "\n",
        "    for line in sys.stdin:\n",
        "        line = line.strip()\n",
        "        day_of_month, count = line.split('\\t')\n",
        "        count = int(count)\n",
        "\n",
        "        if current_day == day_of_month:\n",
        "            total_flights += count\n",
        "        else:\n",
        "            if current_day is not None:\n",
        "                print(f\"{current_day}\\t{total_flights}\")\n",
        "            current_day = day_of_month\n",
        "            total_flights = count\n",
        "\n",
        "    if current_day is not None:\n",
        "        print(f\"{current_day}\\t{total_flights}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k2piYD4Rm4Z",
        "outputId": "8fc0d372-b199-4715-e993-5d25ee96ade6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/reducer_1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asigna permisos de ejecución a los archivos mapper_1.py y reducer_1.py en el directorio /content/.\n",
        "!chmod +x /content/mapper_1.py\n",
        "!chmod +x /content/reducer_1.py"
      ],
      "metadata": {
        "id": "zi8M8-XJRteI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecuta un trabajo de Hadoop Streaming usando el archivo hadoop-streaming-3.3.1.jar.\n",
        "# Utiliza mapper_1.py y reducer_1.py como scripts de mapeo y reducción, respectivamente.\n",
        "# Procesa el archivo de entrada /data/2024_3.csv y guarda los resultados en /data/total_flights_day_month.\n",
        "!hadoop jar hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar \\\n",
        "    -files /content/mapper_1.py,/content/reducer_1.py \\\n",
        "    -mapper \"python3 /content/mapper_1.py\" \\\n",
        "    -reducer \"python3 /content/reducer_1.py\" \\\n",
        "    -input /data/2024_3.csv \\\n",
        "    -output /data/total_flights_day_month"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SNDvYDaR_wA",
        "outputId": "02f707be-44f9-462c-a9b8-3b24ae8efd0d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-16 21:03:02,100 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2024-09-16 21:03:02,281 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2024-09-16 21:03:02,281 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2024-09-16 21:03:02,315 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2024-09-16 21:03:02,843 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2024-09-16 21:03:02,872 INFO mapreduce.JobSubmitter: number of splits:8\n",
            "2024-09-16 21:03:03,199 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local95009450_0001\n",
            "2024-09-16 21:03:03,199 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2024-09-16 21:03:03,727 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapper_1.py as file:/tmp/hadoop-root/mapred/local/job_local95009450_0001_75a1a7c8-e023-4072-a295-9d0dcec0e020/mapper_1.py\n",
            "2024-09-16 21:03:03,766 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer_1.py as file:/tmp/hadoop-root/mapred/local/job_local95009450_0001_2bde302c-b105-43e5-bc38-9e9ba42500f1/reducer_1.py\n",
            "2024-09-16 21:03:03,938 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2024-09-16 21:03:03,940 INFO mapreduce.Job: Running job: job_local95009450_0001\n",
            "2024-09-16 21:03:03,949 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2024-09-16 21:03:04,044 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2024-09-16 21:03:04,057 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:04,057 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:04,115 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2024-09-16 21:03:04,121 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_m_000000_0\n",
            "2024-09-16 21:03:04,151 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:04,153 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:04,176 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:04,188 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:0+33554432\n",
            "2024-09-16 21:03:04,202 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 21:03:04,290 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 21:03:04,290 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 21:03:04,290 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 21:03:04,290 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 21:03:04,290 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 21:03:04,295 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 21:03:04,302 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_1.py]\n",
            "2024-09-16 21:03:04,313 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2024-09-16 21:03:04,316 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2024-09-16 21:03:04,316 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2024-09-16 21:03:04,317 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2024-09-16 21:03:04,317 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2024-09-16 21:03:04,317 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2024-09-16 21:03:04,321 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2024-09-16 21:03:04,321 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2024-09-16 21:03:04,321 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2024-09-16 21:03:04,322 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2024-09-16 21:03:04,323 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2024-09-16 21:03:04,323 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2024-09-16 21:03:04,358 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:04,358 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:04,365 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:04,412 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:04,431 INFO streaming.PipeMapRed: Records R/W=2032/1\n",
            "2024-09-16 21:03:04,556 INFO streaming.PipeMapRed: R/W/S=10000/8725/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:04,948 INFO mapreduce.Job: Job job_local95009450_0001 running in uber mode : false\n",
            "2024-09-16 21:03:04,950 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2024-09-16 21:03:05,158 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:05,160 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:05,164 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 21:03:05,164 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 21:03:05,164 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 21:03:05,164 INFO mapred.MapTask: bufstart = 0; bufend = 346835; bufvoid = 104857600\n",
            "2024-09-16 21:03:05,164 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25920000(103680000); length = 294397/6553600\n",
            "2024-09-16 21:03:05,350 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 21:03:05,367 INFO mapred.Task: Task:attempt_local95009450_0001_m_000000_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:05,371 INFO mapred.LocalJobRunner: Records R/W=2032/1\n",
            "2024-09-16 21:03:05,371 INFO mapred.Task: Task 'attempt_local95009450_0001_m_000000_0' done.\n",
            "2024-09-16 21:03:05,380 INFO mapred.Task: Final Counters for attempt_local95009450_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=33701722\n",
            "\t\tFILE: Number of bytes written=1275414\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=73600\n",
            "\t\tMap output records=73600\n",
            "\t\tMap output bytes=346835\n",
            "\t\tMap output materialized bytes=494041\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=73600\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=308805632\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 21:03:05,381 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_m_000000_0\n",
            "2024-09-16 21:03:05,381 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_m_000001_0\n",
            "2024-09-16 21:03:05,382 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:05,383 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:05,383 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:05,385 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:33554432+33554432\n",
            "2024-09-16 21:03:05,392 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 21:03:05,471 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 21:03:05,471 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 21:03:05,471 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 21:03:05,471 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 21:03:05,471 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 21:03:05,472 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 21:03:05,477 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_1.py]\n",
            "2024-09-16 21:03:05,505 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:05,506 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:05,509 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:05,552 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:05,563 INFO streaming.PipeMapRed: Records R/W=2003/1\n",
            "2024-09-16 21:03:05,629 INFO streaming.PipeMapRed: R/W/S=10000/8703/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:05,953 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2024-09-16 21:03:06,244 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:06,245 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:06,246 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 21:03:06,246 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 21:03:06,246 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 21:03:06,246 INFO mapred.MapTask: bufstart = 0; bufend = 347376; bufvoid = 104857600\n",
            "2024-09-16 21:03:06,246 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25919664(103678656); length = 294733/6553600\n",
            "2024-09-16 21:03:06,338 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 21:03:06,345 INFO mapred.Task: Task:attempt_local95009450_0001_m_000001_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:06,347 INFO mapred.LocalJobRunner: Records R/W=2003/1\n",
            "2024-09-16 21:03:06,347 INFO mapred.Task: Task 'attempt_local95009450_0001_m_000001_0' done.\n",
            "2024-09-16 21:03:06,348 INFO mapred.Task: Final Counters for attempt_local95009450_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=67260857\n",
            "\t\tFILE: Number of bytes written=1770196\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=73684\n",
            "\t\tMap output records=73684\n",
            "\t\tMap output bytes=347376\n",
            "\t\tMap output materialized bytes=494750\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=73684\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=414187520\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 21:03:06,348 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_m_000001_0\n",
            "2024-09-16 21:03:06,348 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_m_000002_0\n",
            "2024-09-16 21:03:06,350 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:06,350 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:06,350 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:06,353 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:67108864+33554432\n",
            "2024-09-16 21:03:06,356 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 21:03:06,439 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 21:03:06,439 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 21:03:06,439 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 21:03:06,439 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 21:03:06,439 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 21:03:06,440 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 21:03:06,444 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_1.py]\n",
            "2024-09-16 21:03:06,464 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:06,465 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:06,465 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:06,506 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:06,518 INFO streaming.PipeMapRed: Records R/W=2024/1\n",
            "2024-09-16 21:03:06,605 INFO streaming.PipeMapRed: R/W/S=10000/8690/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:07,078 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:07,079 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:07,080 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 21:03:07,080 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 21:03:07,080 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 21:03:07,080 INFO mapred.MapTask: bufstart = 0; bufend = 351166; bufvoid = 104857600\n",
            "2024-09-16 21:03:07,080 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25917064(103668256); length = 297333/6553600\n",
            "2024-09-16 21:03:07,151 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 21:03:07,161 INFO mapred.Task: Task:attempt_local95009450_0001_m_000002_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:07,164 INFO mapred.LocalJobRunner: Records R/W=2024/1\n",
            "2024-09-16 21:03:07,165 INFO mapred.Task: Task 'attempt_local95009450_0001_m_000002_0' done.\n",
            "2024-09-16 21:03:07,167 INFO mapred.Task: Final Counters for attempt_local95009450_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=100819992\n",
            "\t\tFILE: Number of bytes written=2270068\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74334\n",
            "\t\tMap output records=74334\n",
            "\t\tMap output bytes=351166\n",
            "\t\tMap output materialized bytes=499840\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74334\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=519569408\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 21:03:07,167 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_m_000002_0\n",
            "2024-09-16 21:03:07,168 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_m_000003_0\n",
            "2024-09-16 21:03:07,173 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:07,173 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:07,173 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:07,180 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:100663296+33554432\n",
            "2024-09-16 21:03:07,185 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 21:03:07,284 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 21:03:07,284 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 21:03:07,284 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 21:03:07,284 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 21:03:07,284 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 21:03:07,285 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 21:03:07,289 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_1.py]\n",
            "2024-09-16 21:03:07,303 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:07,303 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:07,303 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:07,339 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:07,346 INFO streaming.PipeMapRed: Records R/W=2033/1\n",
            "2024-09-16 21:03:07,403 INFO streaming.PipeMapRed: R/W/S=10000/9246/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:07,898 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:07,899 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:07,899 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 21:03:07,899 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 21:03:07,899 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 21:03:07,899 INFO mapred.MapTask: bufstart = 0; bufend = 351024; bufvoid = 104857600\n",
            "2024-09-16 21:03:07,899 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25917484(103669936); length = 296913/6553600\n",
            "2024-09-16 21:03:07,954 INFO mapreduce.Job:  map 38% reduce 0%\n",
            "2024-09-16 21:03:07,961 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 21:03:07,965 INFO mapred.Task: Task:attempt_local95009450_0001_m_000003_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:07,969 INFO mapred.LocalJobRunner: Records R/W=2033/1\n",
            "2024-09-16 21:03:07,969 INFO mapred.Task: Task 'attempt_local95009450_0001_m_000003_0' done.\n",
            "2024-09-16 21:03:07,969 INFO mapred.Task: Final Counters for attempt_local95009450_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=134379127\n",
            "\t\tFILE: Number of bytes written=2769588\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74229\n",
            "\t\tMap output records=74229\n",
            "\t\tMap output bytes=351024\n",
            "\t\tMap output materialized bytes=499488\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74229\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=8\n",
            "\t\tTotal committed heap usage (bytes)=673710080\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 21:03:07,969 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_m_000003_0\n",
            "2024-09-16 21:03:07,970 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_m_000004_0\n",
            "2024-09-16 21:03:07,971 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:07,971 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:07,972 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:07,978 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:134217728+33554432\n",
            "2024-09-16 21:03:07,982 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 21:03:08,002 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 21:03:08,002 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 21:03:08,002 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 21:03:08,002 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 21:03:08,002 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 21:03:08,003 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 21:03:08,008 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_1.py]\n",
            "2024-09-16 21:03:08,031 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,031 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,032 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,072 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,086 INFO streaming.PipeMapRed: Records R/W=2325/1\n",
            "2024-09-16 21:03:08,168 INFO streaming.PipeMapRed: R/W/S=10000/8851/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,644 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:08,645 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:08,645 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 21:03:08,645 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 21:03:08,645 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 21:03:08,645 INFO mapred.MapTask: bufstart = 0; bufend = 346072; bufvoid = 104857600\n",
            "2024-09-16 21:03:08,645 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25917900(103671600); length = 296497/6553600\n",
            "2024-09-16 21:03:08,686 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 21:03:08,694 INFO mapred.Task: Task:attempt_local95009450_0001_m_000004_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:08,698 INFO mapred.LocalJobRunner: Records R/W=2325/1\n",
            "2024-09-16 21:03:08,698 INFO mapred.Task: Task 'attempt_local95009450_0001_m_000004_0' done.\n",
            "2024-09-16 21:03:08,698 INFO mapred.Task: Final Counters for attempt_local95009450_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=167938262\n",
            "\t\tFILE: Number of bytes written=3263948\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74125\n",
            "\t\tMap output records=74125\n",
            "\t\tMap output bytes=346072\n",
            "\t\tMap output materialized bytes=494328\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74125\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=673710080\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 21:03:08,699 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_m_000004_0\n",
            "2024-09-16 21:03:08,699 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_m_000005_0\n",
            "2024-09-16 21:03:08,700 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:08,700 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:08,701 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:08,709 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:167772160+33554432\n",
            "2024-09-16 21:03:08,712 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 21:03:08,789 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 21:03:08,789 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 21:03:08,789 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 21:03:08,789 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 21:03:08,789 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 21:03:08,790 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 21:03:08,794 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_1.py]\n",
            "2024-09-16 21:03:08,819 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,820 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,820 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,845 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,852 INFO streaming.PipeMapRed: Records R/W=2044/1\n",
            "2024-09-16 21:03:08,913 INFO streaming.PipeMapRed: R/W/S=10000/8271/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:08,955 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2024-09-16 21:03:09,388 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:09,388 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:09,389 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 21:03:09,389 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 21:03:09,389 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 21:03:09,389 INFO mapred.MapTask: bufstart = 0; bufend = 352957; bufvoid = 104857600\n",
            "2024-09-16 21:03:09,389 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25917216(103668864); length = 297181/6553600\n",
            "2024-09-16 21:03:09,433 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 21:03:09,437 INFO mapred.Task: Task:attempt_local95009450_0001_m_000005_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:09,440 INFO mapred.LocalJobRunner: Records R/W=2044/1\n",
            "2024-09-16 21:03:09,440 INFO mapred.Task: Task 'attempt_local95009450_0001_m_000005_0' done.\n",
            "2024-09-16 21:03:09,441 INFO mapred.Task: Final Counters for attempt_local95009450_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=201497397\n",
            "\t\tFILE: Number of bytes written=3765535\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74296\n",
            "\t\tMap output records=74296\n",
            "\t\tMap output bytes=352957\n",
            "\t\tMap output materialized bytes=501555\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74296\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=779091968\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 21:03:09,441 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_m_000005_0\n",
            "2024-09-16 21:03:09,441 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_m_000006_0\n",
            "2024-09-16 21:03:09,443 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:09,443 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:09,443 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:09,448 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:201326592+33554432\n",
            "2024-09-16 21:03:09,454 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 21:03:09,527 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 21:03:09,527 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 21:03:09,527 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 21:03:09,527 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 21:03:09,527 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 21:03:09,528 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 21:03:09,532 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_1.py]\n",
            "2024-09-16 21:03:09,540 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:09,540 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:09,541 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:09,577 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:09,587 INFO streaming.PipeMapRed: Records R/W=2016/1\n",
            "2024-09-16 21:03:09,646 INFO streaming.PipeMapRed: R/W/S=10000/9386/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:10,188 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:10,189 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:10,189 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 21:03:10,189 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 21:03:10,189 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 21:03:10,189 INFO mapred.MapTask: bufstart = 0; bufend = 351343; bufvoid = 104857600\n",
            "2024-09-16 21:03:10,189 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25915760(103663040); length = 298637/6553600\n",
            "2024-09-16 21:03:10,230 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 21:03:10,233 INFO mapred.Task: Task:attempt_local95009450_0001_m_000006_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:10,236 INFO mapred.LocalJobRunner: Records R/W=2016/1\n",
            "2024-09-16 21:03:10,236 INFO mapred.Task: Task 'attempt_local95009450_0001_m_000006_0' done.\n",
            "2024-09-16 21:03:10,237 INFO mapred.Task: Final Counters for attempt_local95009450_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=235056532\n",
            "\t\tFILE: Number of bytes written=4266236\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74660\n",
            "\t\tMap output records=74660\n",
            "\t\tMap output bytes=351343\n",
            "\t\tMap output materialized bytes=500669\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74660\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=8\n",
            "\t\tTotal committed heap usage (bytes)=936902656\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 21:03:10,237 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_m_000006_0\n",
            "2024-09-16 21:03:10,237 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_m_000007_0\n",
            "2024-09-16 21:03:10,239 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:10,239 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:10,240 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:10,241 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:234881024+32786772\n",
            "2024-09-16 21:03:10,246 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 21:03:10,263 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 21:03:10,263 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 21:03:10,263 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 21:03:10,263 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 21:03:10,263 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 21:03:10,264 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 21:03:10,268 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_1.py]\n",
            "2024-09-16 21:03:10,275 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:10,275 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:10,276 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:10,311 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:10,321 INFO streaming.PipeMapRed: Records R/W=2345/1\n",
            "2024-09-16 21:03:10,374 INFO streaming.PipeMapRed: R/W/S=10000/9425/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:10,818 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:10,819 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:10,819 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 21:03:10,819 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 21:03:10,819 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 21:03:10,819 INFO mapred.MapTask: bufstart = 0; bufend = 345608; bufvoid = 104857600\n",
            "2024-09-16 21:03:10,819 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25923040(103692160); length = 291357/6553600\n",
            "2024-09-16 21:03:10,855 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 21:03:10,859 INFO mapred.Task: Task:attempt_local95009450_0001_m_000007_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:10,860 INFO mapred.LocalJobRunner: Records R/W=2345/1\n",
            "2024-09-16 21:03:10,860 INFO mapred.Task: Task 'attempt_local95009450_0001_m_000007_0' done.\n",
            "2024-09-16 21:03:10,861 INFO mapred.Task: Final Counters for attempt_local95009450_0001_m_000007_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=267843399\n",
            "\t\tFILE: Number of bytes written=4757562\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=72840\n",
            "\t\tMap output records=72840\n",
            "\t\tMap output bytes=345608\n",
            "\t\tMap output materialized bytes=491294\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=72840\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=936902656\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=32786772\n",
            "2024-09-16 21:03:10,861 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_m_000007_0\n",
            "2024-09-16 21:03:10,861 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2024-09-16 21:03:10,865 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2024-09-16 21:03:10,865 INFO mapred.LocalJobRunner: Starting task: attempt_local95009450_0001_r_000000_0\n",
            "2024-09-16 21:03:10,874 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 21:03:10,874 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 21:03:10,875 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 21:03:10,878 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3db111a4\n",
            "2024-09-16 21:03:10,880 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2024-09-16 21:03:10,903 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2117966208, maxSingleShuffleLimit=529491552, mergeThreshold=1397857792, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2024-09-16 21:03:10,920 INFO reduce.EventFetcher: attempt_local95009450_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2024-09-16 21:03:10,955 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local95009450_0001_m_000004_0 decomp: 494324 len: 494328 to MEMORY\n",
            "2024-09-16 21:03:10,963 INFO reduce.InMemoryMapOutput: Read 494324 bytes from map-output for attempt_local95009450_0001_m_000004_0\n",
            "2024-09-16 21:03:10,965 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 494324, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->494324\n",
            "2024-09-16 21:03:10,974 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local95009450_0001_m_000007_0 decomp: 491290 len: 491294 to MEMORY\n",
            "2024-09-16 21:03:10,975 INFO reduce.InMemoryMapOutput: Read 491290 bytes from map-output for attempt_local95009450_0001_m_000007_0\n",
            "2024-09-16 21:03:10,976 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 491290, inMemoryMapOutputs.size() -> 2, commitMemory -> 494324, usedMemory ->985614\n",
            "2024-09-16 21:03:10,977 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local95009450_0001_m_000001_0 decomp: 494746 len: 494750 to MEMORY\n",
            "2024-09-16 21:03:10,979 INFO reduce.InMemoryMapOutput: Read 494746 bytes from map-output for attempt_local95009450_0001_m_000001_0\n",
            "2024-09-16 21:03:10,979 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 494746, inMemoryMapOutputs.size() -> 3, commitMemory -> 985614, usedMemory ->1480360\n",
            "2024-09-16 21:03:10,981 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local95009450_0001_m_000002_0 decomp: 499836 len: 499840 to MEMORY\n",
            "2024-09-16 21:03:10,982 INFO reduce.InMemoryMapOutput: Read 499836 bytes from map-output for attempt_local95009450_0001_m_000002_0\n",
            "2024-09-16 21:03:10,982 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 499836, inMemoryMapOutputs.size() -> 4, commitMemory -> 1480360, usedMemory ->1980196\n",
            "2024-09-16 21:03:10,984 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local95009450_0001_m_000005_0 decomp: 501551 len: 501555 to MEMORY\n",
            "2024-09-16 21:03:10,985 INFO reduce.InMemoryMapOutput: Read 501551 bytes from map-output for attempt_local95009450_0001_m_000005_0\n",
            "2024-09-16 21:03:10,985 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 501551, inMemoryMapOutputs.size() -> 5, commitMemory -> 1980196, usedMemory ->2481747\n",
            "2024-09-16 21:03:10,987 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local95009450_0001_m_000000_0 decomp: 494037 len: 494041 to MEMORY\n",
            "2024-09-16 21:03:10,988 INFO reduce.InMemoryMapOutput: Read 494037 bytes from map-output for attempt_local95009450_0001_m_000000_0\n",
            "2024-09-16 21:03:10,988 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 494037, inMemoryMapOutputs.size() -> 6, commitMemory -> 2481747, usedMemory ->2975784\n",
            "2024-09-16 21:03:10,990 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local95009450_0001_m_000003_0 decomp: 499484 len: 499488 to MEMORY\n",
            "2024-09-16 21:03:10,991 INFO reduce.InMemoryMapOutput: Read 499484 bytes from map-output for attempt_local95009450_0001_m_000003_0\n",
            "2024-09-16 21:03:10,991 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 499484, inMemoryMapOutputs.size() -> 7, commitMemory -> 2975784, usedMemory ->3475268\n",
            "2024-09-16 21:03:10,993 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local95009450_0001_m_000006_0 decomp: 500665 len: 500669 to MEMORY\n",
            "2024-09-16 21:03:10,994 INFO reduce.InMemoryMapOutput: Read 500665 bytes from map-output for attempt_local95009450_0001_m_000006_0\n",
            "2024-09-16 21:03:10,994 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 500665, inMemoryMapOutputs.size() -> 8, commitMemory -> 3475268, usedMemory ->3975933\n",
            "2024-09-16 21:03:10,996 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2024-09-16 21:03:10,997 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
            "2024-09-16 21:03:10,997 INFO reduce.MergeManagerImpl: finalMerge called with 8 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2024-09-16 21:03:11,010 INFO mapred.Merger: Merging 8 sorted segments\n",
            "2024-09-16 21:03:11,011 INFO mapred.Merger: Down to the last merge-pass, with 8 segments left of total size: 3975890 bytes\n",
            "2024-09-16 21:03:11,304 INFO reduce.MergeManagerImpl: Merged 8 segments, 3975933 bytes to disk to satisfy reduce memory limit\n",
            "2024-09-16 21:03:11,305 INFO reduce.MergeManagerImpl: Merging 1 files, 3975923 bytes from disk\n",
            "2024-09-16 21:03:11,307 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2024-09-16 21:03:11,307 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2024-09-16 21:03:11,308 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3975904 bytes\n",
            "2024-09-16 21:03:11,312 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
            "2024-09-16 21:03:11,319 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/reducer_1.py]\n",
            "2024-09-16 21:03:11,323 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2024-09-16 21:03:11,325 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2024-09-16 21:03:11,370 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:11,370 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:11,371 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:11,390 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:11,411 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:11,698 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:12,026 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:12,215 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:12,327 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 21:03:12,419 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:500000=500000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2024-09-16 21:03:12,514 INFO streaming.PipeMapRed: Records R/W=591768/1\n",
            "2024-09-16 21:03:12,517 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 21:03:12,518 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 21:03:12,519 INFO mapred.Task: Task:attempt_local95009450_0001_r_000000_0 is done. And is in the process of committing\n",
            "2024-09-16 21:03:12,520 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
            "2024-09-16 21:03:12,521 INFO mapred.Task: Task attempt_local95009450_0001_r_000000_0 is allowed to commit now\n",
            "2024-09-16 21:03:12,522 INFO output.FileOutputCommitter: Saved output of task 'attempt_local95009450_0001_r_000000_0' to file:/data/total_flights_day_month\n",
            "2024-09-16 21:03:12,525 INFO mapred.LocalJobRunner: Records R/W=591768/1 > reduce\n",
            "2024-09-16 21:03:12,525 INFO mapred.Task: Task 'attempt_local95009450_0001_r_000000_0' done.\n",
            "2024-09-16 21:03:12,525 INFO mapred.Task: Final Counters for attempt_local95009450_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=275795543\n",
            "\t\tFILE: Number of bytes written=8733782\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=32\n",
            "\t\tReduce shuffle bytes=3975965\n",
            "\t\tReduce input records=591768\n",
            "\t\tReduce output records=32\n",
            "\t\tSpilled Records=591768\n",
            "\t\tShuffled Maps =8\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=8\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=936902656\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=297\n",
            "2024-09-16 21:03:12,526 INFO mapred.LocalJobRunner: Finishing task: attempt_local95009450_0001_r_000000_0\n",
            "2024-09-16 21:03:12,526 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2024-09-16 21:03:12,958 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2024-09-16 21:03:12,958 INFO mapreduce.Job: Job job_local95009450_0001 completed successfully\n",
            "2024-09-16 21:03:12,986 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1484292831\n",
            "\t\tFILE: Number of bytes written=32872329\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=591768\n",
            "\t\tMap output records=591768\n",
            "\t\tMap output bytes=2792381\n",
            "\t\tMap output materialized bytes=3975965\n",
            "\t\tInput split bytes=584\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=32\n",
            "\t\tReduce shuffle bytes=3975965\n",
            "\t\tReduce input records=591768\n",
            "\t\tReduce output records=32\n",
            "\t\tSpilled Records=1183536\n",
            "\t\tShuffled Maps =8\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=8\n",
            "\t\tGC time elapsed (ms)=16\n",
            "\t\tTotal committed heap usage (bytes)=6179782656\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=267696468\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=297\n",
            "2024-09-16 21:03:12,986 INFO streaming.StreamJob: Output directory: /data/total_flights_day_month\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista los archivos y directorios en /data/total_flights_day_month en HDFS.\n",
        "!hdfs dfs -ls /data/total_flights_day_month"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-Zq0RVUcyqv",
        "outputId": "d032ecea-aa8f-4ad2-a500-51f99d5e9955"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 items\n",
            "-rw-r--r--   1 root root          0 2024-09-16 21:03 /data/total_flights_day_month/_SUCCESS\n",
            "-rw-r--r--   1 root root        285 2024-09-16 21:03 /data/total_flights_day_month/part-00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra el contenido de todos los archivos que comienzan con 'part-' en el directorio /data/total_flights_day_month en HDFS.\n",
        "!hdfs dfs -cat /data/total_flights_day_month/part-*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xbyLiPvc2LX",
        "outputId": "81b715f8-74e0-4968-c304-f1bab98a39de"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"DayofMonth\"\t1\n",
            "1\t19157\n",
            "10\t19623\n",
            "11\t19977\n",
            "12\t18541\n",
            "13\t18804\n",
            "14\t20107\n",
            "15\t20120\n",
            "16\t17720\n",
            "17\t19828\n",
            "18\t20102\n",
            "19\t18604\n",
            "2\t16492\n",
            "20\t18862\n",
            "21\t20130\n",
            "22\t20132\n",
            "23\t17718\n",
            "24\t19802\n",
            "25\t20096\n",
            "26\t18601\n",
            "27\t18863\n",
            "28\t20129\n",
            "29\t20134\n",
            "3\t19079\n",
            "30\t17714\n",
            "31\t19691\n",
            "4\t19085\n",
            "5\t17603\n",
            "6\t17967\n",
            "7\t19830\n",
            "8\t19882\n",
            "9\t17374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conteo total de vuelos que salieron de los diferentes orígenes (campo OriginAirportID). Denomina al maper como maper_2.py."
      ],
      "metadata": {
        "id": "BgupUd3UkxiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/mapper_2.py\n",
        "\n",
        "import sys\n",
        "\n",
        "def mapper():\n",
        "    \"\"\"Función mapper que procesa entradas de datos de vuelos y emite el ID del aeropuerto de origen.\"\"\"\n",
        "    for line in sys.stdin:\n",
        "        # Eliminar espacios en blanco y dividir la línea en campos\n",
        "        line = line.strip()\n",
        "        fields = line.split(',')\n",
        "\n",
        "        # Asegurarse de que la línea tenga suficientes campos\n",
        "        if len(fields) > 15:  # Ajusta según el número total de campos en tus datos\n",
        "            origin_airport_id = fields[12]  # Suponiendo que OriginAirportID es el campo en la posición 12\n",
        "            if origin_airport_id.isdigit():\n",
        "                # Emitir la clave y el valor\n",
        "                print(f\"{origin_airport_id}\\t1\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mapper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe4t7_BBdLCP",
        "outputId": "870c3ed1-3d36-4f94-ce32-7080e2aebc60"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/mapper_2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conteo total de vuelos que salieron de los diferentes orígenes (campo OriginAirportID). Denomina al reducer como reducer_2.py."
      ],
      "metadata": {
        "id": "lbART_CLk265"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/reducer_2.py\n",
        "\n",
        "import sys\n",
        "\n",
        "def reducer():\n",
        "    \"\"\"Función reducer que suma el conteo de vuelos por ID de aeropuerto.\"\"\"\n",
        "    current_airport_id = None\n",
        "    total_flights = 0\n",
        "\n",
        "    for line in sys.stdin:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        airport_id, count = line.split(\"\\t\")\n",
        "        count = int(count)\n",
        "\n",
        "        if current_airport_id == airport_id:\n",
        "            total_flights += count\n",
        "        else:\n",
        "            if current_airport_id is not None:\n",
        "                # Imprimir el resultado para el aeropuerto anterior\n",
        "                print(f\"{current_airport_id}\\t{total_flights}\")\n",
        "            current_airport_id = airport_id\n",
        "            total_flights = count\n",
        "\n",
        "    # Imprimir el resultado para el último aeropuerto\n",
        "    if current_airport_id is not None:\n",
        "        print(f\"{current_airport_id}\\t{total_flights}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    reducer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcWNQrmPdNpQ",
        "outputId": "0c8c449e-85e8-4aa8-a760-3ab85f18c198"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/reducer_2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asigna permisos de ejecución a los archivos mapper_2.py y reducer_2.py en el directorio /content/.\n",
        "!chmod +x /content/mapper_2.py\n",
        "!chmod +x /content/reducer_2.py"
      ],
      "metadata": {
        "id": "Ud6onLukdVTP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecuta un trabajo de Hadoop Streaming usando el archivo hadoop-streaming-3.3.1.jar.\n",
        "# El trabajo usa mapper_2.py y reducer_2.py como scripts de mapeo y reducción, respectivamente.\n",
        "# Procesa el archivo de entrada /data/2024_3.csv y guarda los resultados en /data/total_flights_airport_id.\n",
        "!hadoop jar hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar \\\n",
        "    -files /content/mapper_2.py,/content/reducer_2.py \\\n",
        "    -mapper \"python3 /content/mapper_2.py\" \\\n",
        "    -reducer \"python3 /content/reducer_2.py\" \\\n",
        "    -input /data/2024_3.csv \\\n",
        "    -output /data/total_flights_airport_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHdvAOv1daFv",
        "outputId": "23d9a73e-1771-4210-9f43-741f1337878b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-16 20:59:05,008 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2024-09-16 20:59:05,260 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2024-09-16 20:59:05,261 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2024-09-16 20:59:05,298 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2024-09-16 20:59:05,901 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2024-09-16 20:59:05,928 INFO mapreduce.JobSubmitter: number of splits:8\n",
            "2024-09-16 20:59:06,255 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1705715392_0001\n",
            "2024-09-16 20:59:06,255 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2024-09-16 20:59:06,834 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapper_2.py as file:/tmp/hadoop-root/mapred/local/job_local1705715392_0001_6056310b-2a8e-446f-985e-7246b7bdb288/mapper_2.py\n",
            "2024-09-16 20:59:06,856 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer_2.py as file:/tmp/hadoop-root/mapred/local/job_local1705715392_0001_e1ff8641-456f-4d82-b8cd-b5509cce4af3/reducer_2.py\n",
            "2024-09-16 20:59:07,068 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2024-09-16 20:59:07,071 INFO mapreduce.Job: Running job: job_local1705715392_0001\n",
            "2024-09-16 20:59:07,080 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2024-09-16 20:59:07,191 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2024-09-16 20:59:07,199 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:07,199 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:07,248 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2024-09-16 20:59:07,253 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_m_000000_0\n",
            "2024-09-16 20:59:07,288 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:07,297 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:07,347 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:07,376 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:0+33554432\n",
            "2024-09-16 20:59:07,413 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 20:59:07,643 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 20:59:07,643 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 20:59:07,643 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 20:59:07,643 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 20:59:07,643 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 20:59:07,672 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 20:59:07,683 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_2.py]\n",
            "2024-09-16 20:59:07,688 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2024-09-16 20:59:07,690 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2024-09-16 20:59:07,690 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2024-09-16 20:59:07,691 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2024-09-16 20:59:07,691 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2024-09-16 20:59:07,691 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2024-09-16 20:59:07,693 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2024-09-16 20:59:07,693 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2024-09-16 20:59:07,693 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2024-09-16 20:59:07,695 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2024-09-16 20:59:07,696 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2024-09-16 20:59:07,696 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2024-09-16 20:59:07,730 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:07,731 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:07,735 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:07,804 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:07,811 INFO streaming.PipeMapRed: Records R/W=1159/1\n",
            "2024-09-16 20:59:08,073 INFO streaming.PipeMapRed: R/W/S=10000/9828/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:08,078 INFO mapreduce.Job: Job job_local1705715392_0001 running in uber mode : false\n",
            "2024-09-16 20:59:08,080 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2024-09-16 20:59:09,025 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:09,026 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:09,036 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 20:59:09,036 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 20:59:09,036 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 20:59:09,036 INFO mapred.MapTask: bufstart = 0; bufend = 735990; bufvoid = 104857600\n",
            "2024-09-16 20:59:09,036 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25920004(103680016); length = 294393/6553600\n",
            "2024-09-16 20:59:09,345 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 20:59:09,389 INFO mapred.Task: Task:attempt_local1705715392_0001_m_000000_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:09,393 INFO mapred.LocalJobRunner: Records R/W=1159/1\n",
            "2024-09-16 20:59:09,393 INFO mapred.Task: Task 'attempt_local1705715392_0001_m_000000_0' done.\n",
            "2024-09-16 20:59:09,404 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=33702144\n",
            "\t\tFILE: Number of bytes written=1671215\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=73600\n",
            "\t\tMap output records=73599\n",
            "\t\tMap output bytes=735990\n",
            "\t\tMap output materialized bytes=883194\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=73599\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=310902784\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 20:59:09,404 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_m_000000_0\n",
            "2024-09-16 20:59:09,404 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_m_000001_0\n",
            "2024-09-16 20:59:09,414 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:09,414 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:09,415 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:09,421 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:33554432+33554432\n",
            "2024-09-16 20:59:09,428 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 20:59:09,649 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 20:59:09,649 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 20:59:09,650 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 20:59:09,651 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 20:59:09,651 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 20:59:09,652 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 20:59:09,663 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_2.py]\n",
            "2024-09-16 20:59:09,694 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:09,694 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:09,696 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:09,784 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:09,788 INFO streaming.PipeMapRed: Records R/W=1147/1\n",
            "2024-09-16 20:59:09,950 INFO streaming.PipeMapRed: R/W/S=10000/9009/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:10,094 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2024-09-16 20:59:10,691 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:10,692 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:10,693 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 20:59:10,693 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 20:59:10,693 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 20:59:10,693 INFO mapred.MapTask: bufstart = 0; bufend = 736840; bufvoid = 104857600\n",
            "2024-09-16 20:59:10,693 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25919664(103678656); length = 294733/6553600\n",
            "2024-09-16 20:59:10,798 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 20:59:10,806 INFO mapred.Task: Task:attempt_local1705715392_0001_m_000001_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:10,808 INFO mapred.LocalJobRunner: Records R/W=1147/1\n",
            "2024-09-16 20:59:10,808 INFO mapred.Task: Task 'attempt_local1705715392_0001_m_000001_0' done.\n",
            "2024-09-16 20:59:10,809 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=67261279\n",
            "\t\tFILE: Number of bytes written=2555461\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=73684\n",
            "\t\tMap output records=73684\n",
            "\t\tMap output bytes=736840\n",
            "\t\tMap output materialized bytes=884214\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=73684\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=416284672\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 20:59:10,809 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_m_000001_0\n",
            "2024-09-16 20:59:10,809 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_m_000002_0\n",
            "2024-09-16 20:59:10,811 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:10,811 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:10,811 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:10,815 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:67108864+33554432\n",
            "2024-09-16 20:59:10,818 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 20:59:10,983 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 20:59:10,984 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 20:59:10,984 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 20:59:10,984 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 20:59:10,985 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 20:59:10,986 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 20:59:10,990 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_2.py]\n",
            "2024-09-16 20:59:11,016 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,016 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,017 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,061 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,063 INFO streaming.PipeMapRed: Records R/W=1159/1\n",
            "2024-09-16 20:59:11,151 INFO streaming.PipeMapRed: R/W/S=10000/9009/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,630 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:11,631 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:11,632 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 20:59:11,632 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 20:59:11,632 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 20:59:11,632 INFO mapred.MapTask: bufstart = 0; bufend = 743340; bufvoid = 104857600\n",
            "2024-09-16 20:59:11,632 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25917064(103668256); length = 297333/6553600\n",
            "2024-09-16 20:59:11,705 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 20:59:11,715 INFO mapred.Task: Task:attempt_local1705715392_0001_m_000002_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:11,717 INFO mapred.LocalJobRunner: Records R/W=1159/1\n",
            "2024-09-16 20:59:11,717 INFO mapred.Task: Task 'attempt_local1705715392_0001_m_000002_0' done.\n",
            "2024-09-16 20:59:11,717 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=100820414\n",
            "\t\tFILE: Number of bytes written=3447507\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74334\n",
            "\t\tMap output records=74334\n",
            "\t\tMap output bytes=743340\n",
            "\t\tMap output materialized bytes=892014\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74334\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=521666560\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 20:59:11,718 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_m_000002_0\n",
            "2024-09-16 20:59:11,718 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_m_000003_0\n",
            "2024-09-16 20:59:11,719 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:11,719 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:11,720 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:11,726 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:100663296+33554432\n",
            "2024-09-16 20:59:11,730 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 20:59:11,908 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 20:59:11,908 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 20:59:11,908 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 20:59:11,908 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 20:59:11,908 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 20:59:11,909 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 20:59:11,916 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_2.py]\n",
            "2024-09-16 20:59:11,937 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,937 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,937 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,969 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:11,970 INFO streaming.PipeMapRed: Records R/W=1161/1\n",
            "2024-09-16 20:59:12,036 INFO streaming.PipeMapRed: R/W/S=10000/9009/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:12,524 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:12,525 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:12,526 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 20:59:12,526 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 20:59:12,526 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 20:59:12,526 INFO mapred.MapTask: bufstart = 0; bufend = 742290; bufvoid = 104857600\n",
            "2024-09-16 20:59:12,526 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25917484(103669936); length = 296913/6553600\n",
            "2024-09-16 20:59:12,609 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 20:59:12,613 INFO mapred.Task: Task:attempt_local1705715392_0001_m_000003_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:12,614 INFO mapred.LocalJobRunner: Records R/W=1161/1\n",
            "2024-09-16 20:59:12,614 INFO mapred.Task: Task 'attempt_local1705715392_0001_m_000003_0' done.\n",
            "2024-09-16 20:59:12,616 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=134379549\n",
            "\t\tFILE: Number of bytes written=4338293\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74229\n",
            "\t\tMap output records=74229\n",
            "\t\tMap output bytes=742290\n",
            "\t\tMap output materialized bytes=890754\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74229\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=627048448\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 20:59:12,616 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_m_000003_0\n",
            "2024-09-16 20:59:12,616 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_m_000004_0\n",
            "2024-09-16 20:59:12,618 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:12,618 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:12,618 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:12,620 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:134217728+33554432\n",
            "2024-09-16 20:59:12,623 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 20:59:12,779 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 20:59:12,779 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 20:59:12,779 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 20:59:12,779 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 20:59:12,779 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 20:59:12,780 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 20:59:12,785 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_2.py]\n",
            "2024-09-16 20:59:12,816 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:12,817 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:12,817 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:12,881 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:12,895 INFO streaming.PipeMapRed: Records R/W=1166/1\n",
            "2024-09-16 20:59:12,988 INFO streaming.PipeMapRed: R/W/S=10000/9009/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:13,493 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:13,493 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:13,494 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 20:59:13,494 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 20:59:13,494 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 20:59:13,494 INFO mapred.MapTask: bufstart = 0; bufend = 741250; bufvoid = 104857600\n",
            "2024-09-16 20:59:13,494 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25917900(103671600); length = 296497/6553600\n",
            "2024-09-16 20:59:13,572 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 20:59:13,576 INFO mapred.Task: Task:attempt_local1705715392_0001_m_000004_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:13,578 INFO mapred.LocalJobRunner: Records R/W=1166/1\n",
            "2024-09-16 20:59:13,578 INFO mapred.Task: Task 'attempt_local1705715392_0001_m_000004_0' done.\n",
            "2024-09-16 20:59:13,578 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=167938684\n",
            "\t\tFILE: Number of bytes written=5227831\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74125\n",
            "\t\tMap output records=74125\n",
            "\t\tMap output bytes=741250\n",
            "\t\tMap output materialized bytes=889506\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74125\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=11\n",
            "\t\tTotal committed heap usage (bytes)=776994816\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 20:59:13,578 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_m_000004_0\n",
            "2024-09-16 20:59:13,579 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_m_000005_0\n",
            "2024-09-16 20:59:13,581 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:13,581 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:13,581 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:13,585 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:167772160+33554432\n",
            "2024-09-16 20:59:13,588 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 20:59:13,613 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 20:59:13,613 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 20:59:13,613 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 20:59:13,613 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 20:59:13,613 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 20:59:13,614 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 20:59:13,618 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_2.py]\n",
            "2024-09-16 20:59:13,640 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:13,641 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:13,641 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:13,674 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:13,676 INFO streaming.PipeMapRed: Records R/W=1163/1\n",
            "2024-09-16 20:59:13,747 INFO streaming.PipeMapRed: R/W/S=10000/9009/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:14,253 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:14,253 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:14,254 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 20:59:14,254 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 20:59:14,254 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 20:59:14,254 INFO mapred.MapTask: bufstart = 0; bufend = 742960; bufvoid = 104857600\n",
            "2024-09-16 20:59:14,254 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25917216(103668864); length = 297181/6553600\n",
            "2024-09-16 20:59:14,321 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 20:59:14,330 INFO mapred.Task: Task:attempt_local1705715392_0001_m_000005_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:14,333 INFO mapred.LocalJobRunner: Records R/W=1163/1\n",
            "2024-09-16 20:59:14,333 INFO mapred.Task: Task 'attempt_local1705715392_0001_m_000005_0' done.\n",
            "2024-09-16 20:59:14,334 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=201497819\n",
            "\t\tFILE: Number of bytes written=6119421\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74296\n",
            "\t\tMap output records=74296\n",
            "\t\tMap output bytes=742960\n",
            "\t\tMap output materialized bytes=891558\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74296\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=776994816\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 20:59:14,339 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_m_000005_0\n",
            "2024-09-16 20:59:14,340 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_m_000006_0\n",
            "2024-09-16 20:59:14,342 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:14,342 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:14,342 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:14,345 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:201326592+33554432\n",
            "2024-09-16 20:59:14,353 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 20:59:14,511 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 20:59:14,511 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 20:59:14,511 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 20:59:14,512 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 20:59:14,512 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 20:59:14,512 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 20:59:14,522 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_2.py]\n",
            "2024-09-16 20:59:14,531 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:14,532 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:14,532 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:14,571 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:14,575 INFO streaming.PipeMapRed: Records R/W=1156/1\n",
            "2024-09-16 20:59:14,642 INFO streaming.PipeMapRed: R/W/S=10000/9009/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:15,154 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:15,154 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:15,155 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 20:59:15,155 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 20:59:15,155 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 20:59:15,155 INFO mapred.MapTask: bufstart = 0; bufend = 746600; bufvoid = 104857600\n",
            "2024-09-16 20:59:15,155 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25915760(103663040); length = 298637/6553600\n",
            "2024-09-16 20:59:15,232 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 20:59:15,236 INFO mapred.Task: Task:attempt_local1705715392_0001_m_000006_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:15,238 INFO mapred.LocalJobRunner: Records R/W=1156/1\n",
            "2024-09-16 20:59:15,238 INFO mapred.Task: Task 'attempt_local1705715392_0001_m_000006_0' done.\n",
            "2024-09-16 20:59:15,238 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=235056954\n",
            "\t\tFILE: Number of bytes written=7015379\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=74660\n",
            "\t\tMap output records=74660\n",
            "\t\tMap output bytes=746600\n",
            "\t\tMap output materialized bytes=895926\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=74660\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=882376704\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2024-09-16 20:59:15,239 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_m_000006_0\n",
            "2024-09-16 20:59:15,239 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_m_000007_0\n",
            "2024-09-16 20:59:15,240 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:15,240 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:15,241 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:15,245 INFO mapred.MapTask: Processing split: file:/data/2024_3.csv:234881024+32786772\n",
            "2024-09-16 20:59:15,249 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2024-09-16 20:59:15,402 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2024-09-16 20:59:15,402 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2024-09-16 20:59:15,402 INFO mapred.MapTask: soft limit at 83886080\n",
            "2024-09-16 20:59:15,402 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2024-09-16 20:59:15,402 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2024-09-16 20:59:15,403 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2024-09-16 20:59:15,412 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/mapper_2.py]\n",
            "2024-09-16 20:59:15,424 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:15,424 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:15,424 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:15,460 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:15,461 INFO streaming.PipeMapRed: Records R/W=1172/1\n",
            "2024-09-16 20:59:15,536 INFO streaming.PipeMapRed: R/W/S=10000/9009/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:16,020 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:16,021 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:16,021 INFO mapred.LocalJobRunner: \n",
            "2024-09-16 20:59:16,022 INFO mapred.MapTask: Starting flush of map output\n",
            "2024-09-16 20:59:16,022 INFO mapred.MapTask: Spilling map output\n",
            "2024-09-16 20:59:16,022 INFO mapred.MapTask: bufstart = 0; bufend = 728400; bufvoid = 104857600\n",
            "2024-09-16 20:59:16,022 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25923040(103692160); length = 291357/6553600\n",
            "2024-09-16 20:59:16,072 INFO mapred.MapTask: Finished spill 0\n",
            "2024-09-16 20:59:16,075 INFO mapred.Task: Task:attempt_local1705715392_0001_m_000007_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:16,079 INFO mapred.LocalJobRunner: Records R/W=1172/1\n",
            "2024-09-16 20:59:16,080 INFO mapred.Task: Task 'attempt_local1705715392_0001_m_000007_0' done.\n",
            "2024-09-16 20:59:16,083 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_m_000007_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=267843821\n",
            "\t\tFILE: Number of bytes written=7889497\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=72840\n",
            "\t\tMap output records=72840\n",
            "\t\tMap output bytes=728400\n",
            "\t\tMap output materialized bytes=874086\n",
            "\t\tInput split bytes=73\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=72840\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=9\n",
            "\t\tTotal committed heap usage (bytes)=1044381696\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=32786772\n",
            "2024-09-16 20:59:16,084 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_m_000007_0\n",
            "2024-09-16 20:59:16,084 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2024-09-16 20:59:16,088 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2024-09-16 20:59:16,088 INFO mapred.LocalJobRunner: Starting task: attempt_local1705715392_0001_r_000000_0\n",
            "2024-09-16 20:59:16,099 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2024-09-16 20:59:16,099 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2024-09-16 20:59:16,099 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2024-09-16 20:59:16,103 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1286249f\n",
            "2024-09-16 20:59:16,105 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2024-09-16 20:59:16,139 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2117966208, maxSingleShuffleLimit=529491552, mergeThreshold=1397857792, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2024-09-16 20:59:16,143 INFO reduce.EventFetcher: attempt_local1705715392_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2024-09-16 20:59:16,178 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1705715392_0001_m_000003_0 decomp: 890750 len: 890754 to MEMORY\n",
            "2024-09-16 20:59:16,183 INFO reduce.InMemoryMapOutput: Read 890750 bytes from map-output for attempt_local1705715392_0001_m_000003_0\n",
            "2024-09-16 20:59:16,185 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 890750, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->890750\n",
            "2024-09-16 20:59:16,189 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1705715392_0001_m_000000_0 decomp: 883190 len: 883194 to MEMORY\n",
            "2024-09-16 20:59:16,190 INFO reduce.InMemoryMapOutput: Read 883190 bytes from map-output for attempt_local1705715392_0001_m_000000_0\n",
            "2024-09-16 20:59:16,190 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 883190, inMemoryMapOutputs.size() -> 2, commitMemory -> 890750, usedMemory ->1773940\n",
            "2024-09-16 20:59:16,192 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1705715392_0001_m_000006_0 decomp: 895922 len: 895926 to MEMORY\n",
            "2024-09-16 20:59:16,193 INFO reduce.InMemoryMapOutput: Read 895922 bytes from map-output for attempt_local1705715392_0001_m_000006_0\n",
            "2024-09-16 20:59:16,198 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 895922, inMemoryMapOutputs.size() -> 3, commitMemory -> 1773940, usedMemory ->2669862\n",
            "2024-09-16 20:59:16,200 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1705715392_0001_m_000005_0 decomp: 891554 len: 891558 to MEMORY\n",
            "2024-09-16 20:59:16,209 INFO reduce.InMemoryMapOutput: Read 891554 bytes from map-output for attempt_local1705715392_0001_m_000005_0\n",
            "2024-09-16 20:59:16,211 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 891554, inMemoryMapOutputs.size() -> 4, commitMemory -> 2669862, usedMemory ->3561416\n",
            "2024-09-16 20:59:16,213 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1705715392_0001_m_000002_0 decomp: 892010 len: 892014 to MEMORY\n",
            "2024-09-16 20:59:16,214 INFO reduce.InMemoryMapOutput: Read 892010 bytes from map-output for attempt_local1705715392_0001_m_000002_0\n",
            "2024-09-16 20:59:16,214 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 892010, inMemoryMapOutputs.size() -> 5, commitMemory -> 3561416, usedMemory ->4453426\n",
            "2024-09-16 20:59:16,218 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1705715392_0001_m_000001_0 decomp: 884210 len: 884214 to MEMORY\n",
            "2024-09-16 20:59:16,219 INFO reduce.InMemoryMapOutput: Read 884210 bytes from map-output for attempt_local1705715392_0001_m_000001_0\n",
            "2024-09-16 20:59:16,220 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 884210, inMemoryMapOutputs.size() -> 6, commitMemory -> 4453426, usedMemory ->5337636\n",
            "2024-09-16 20:59:16,223 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1705715392_0001_m_000007_0 decomp: 874082 len: 874086 to MEMORY\n",
            "2024-09-16 20:59:16,224 INFO reduce.InMemoryMapOutput: Read 874082 bytes from map-output for attempt_local1705715392_0001_m_000007_0\n",
            "2024-09-16 20:59:16,225 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 874082, inMemoryMapOutputs.size() -> 7, commitMemory -> 5337636, usedMemory ->6211718\n",
            "2024-09-16 20:59:16,228 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1705715392_0001_m_000004_0 decomp: 889502 len: 889506 to MEMORY\n",
            "2024-09-16 20:59:16,229 INFO reduce.InMemoryMapOutput: Read 889502 bytes from map-output for attempt_local1705715392_0001_m_000004_0\n",
            "2024-09-16 20:59:16,229 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 889502, inMemoryMapOutputs.size() -> 8, commitMemory -> 6211718, usedMemory ->7101220\n",
            "2024-09-16 20:59:16,231 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2024-09-16 20:59:16,232 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
            "2024-09-16 20:59:16,232 INFO reduce.MergeManagerImpl: finalMerge called with 8 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2024-09-16 20:59:16,241 INFO mapred.Merger: Merging 8 sorted segments\n",
            "2024-09-16 20:59:16,241 INFO mapred.Merger: Down to the last merge-pass, with 8 segments left of total size: 7101140 bytes\n",
            "2024-09-16 20:59:16,507 INFO reduce.MergeManagerImpl: Merged 8 segments, 7101220 bytes to disk to satisfy reduce memory limit\n",
            "2024-09-16 20:59:16,508 INFO reduce.MergeManagerImpl: Merging 1 files, 7101210 bytes from disk\n",
            "2024-09-16 20:59:16,509 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2024-09-16 20:59:16,509 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2024-09-16 20:59:16,510 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7101196 bytes\n",
            "2024-09-16 20:59:16,510 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
            "2024-09-16 20:59:16,524 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, /content/reducer_2.py]\n",
            "2024-09-16 20:59:16,528 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2024-09-16 20:59:16,529 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2024-09-16 20:59:16,556 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:16,556 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:16,557 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:16,574 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:16,618 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:16,853 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:17,051 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:17,210 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:17,371 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2024-09-16 20:59:17,539 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:500000=500000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2024-09-16 20:59:17,708 INFO streaming.PipeMapRed: Records R/W=591767/1\n",
            "2024-09-16 20:59:17,716 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2024-09-16 20:59:17,719 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2024-09-16 20:59:17,720 INFO mapred.Task: Task:attempt_local1705715392_0001_r_000000_0 is done. And is in the process of committing\n",
            "2024-09-16 20:59:17,721 INFO mapred.LocalJobRunner: 8 / 8 copied.\n",
            "2024-09-16 20:59:17,721 INFO mapred.Task: Task attempt_local1705715392_0001_r_000000_0 is allowed to commit now\n",
            "2024-09-16 20:59:17,723 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1705715392_0001_r_000000_0' to file:/data/total_flights_airport_id\n",
            "2024-09-16 20:59:17,723 INFO mapred.LocalJobRunner: Records R/W=591767/1 > reduce\n",
            "2024-09-16 20:59:17,724 INFO mapred.Task: Task 'attempt_local1705715392_0001_r_000000_0' done.\n",
            "2024-09-16 20:59:17,724 INFO mapred.Task: Final Counters for attempt_local1705715392_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=282046539\n",
            "\t\tFILE: Number of bytes written=14994714\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=331\n",
            "\t\tReduce shuffle bytes=7101252\n",
            "\t\tReduce input records=591767\n",
            "\t\tReduce output records=331\n",
            "\t\tSpilled Records=591767\n",
            "\t\tShuffled Maps =8\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=8\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1044381696\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=4007\n",
            "2024-09-16 20:59:17,724 INFO mapred.LocalJobRunner: Finishing task: attempt_local1705715392_0001_r_000000_0\n",
            "2024-09-16 20:59:17,724 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2024-09-16 20:59:18,099 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2024-09-16 20:59:18,100 INFO mapreduce.Job: Job job_local1705715392_0001 completed successfully\n",
            "2024-09-16 20:59:18,124 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1490547203\n",
            "\t\tFILE: Number of bytes written=53259318\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=591768\n",
            "\t\tMap output records=591767\n",
            "\t\tMap output bytes=5917670\n",
            "\t\tMap output materialized bytes=7101252\n",
            "\t\tInput split bytes=584\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=331\n",
            "\t\tReduce shuffle bytes=7101252\n",
            "\t\tReduce input records=591767\n",
            "\t\tReduce output records=331\n",
            "\t\tSpilled Records=1183534\n",
            "\t\tShuffled Maps =8\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=8\n",
            "\t\tGC time elapsed (ms)=20\n",
            "\t\tTotal committed heap usage (bytes)=6401032192\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=267696468\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=4007\n",
            "2024-09-16 20:59:18,130 INFO streaming.StreamJob: Output directory: /data/total_flights_airport_id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra el contenido del archivo /data/total_flights_airport_id/part-00000 en HDFS, que es parte de la salida del trabajo de Hadoop Streaming.\n",
        "!hdfs dfs -cat /data/total_flights_airport_id/part-00000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnouX3i6dyUP",
        "outputId": "4c79a375-2e29-4eaa-e4eb-4796c3ffb24f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1013506\t392\n",
            "1013603\t147\n",
            "1014005\t1893\n",
            "1014106\t62\n",
            "1014602\t62\n",
            "1015502\t93\n",
            "1015706\t148\n",
            "1015804\t327\n",
            "1016506\t9\n",
            "1017004\t60\n",
            "1018502\t155\n",
            "1020803\t252\n",
            "1025702\t1031\n",
            "1027506\t62\n",
            "1027903\t427\n",
            "1029906\t1302\n",
            "1033302\t54\n",
            "1037205\t1041\n",
            "1039707\t28459\n",
            "1040805\t530\n",
            "1042302\t7154\n",
            "1043106\t862\n",
            "1043405\t117\n",
            "1046602\t611\n",
            "1046902\t88\n",
            "1052907\t1757\n",
            "1055102\t62\n",
            "1055803\t54\n",
            "1056103\t187\n",
            "1057705\t31\n",
            "1058102\t257\n",
            "1059904\t1372\n",
            "1061705\t58\n",
            "1062003\t276\n",
            "1062702\t292\n",
            "1063104\t62\n",
            "1066602\t255\n",
            "1067603\t94\n",
            "1068503\t142\n",
            "1069302\t8287\n",
            "1071302\t1723\n",
            "1072102\t11324\n",
            "1072805\t62\n",
            "1073103\t62\n",
            "1073203\t245\n",
            "1073907\t53\n",
            "1074706\t189\n",
            "1075405\t31\n",
            "1077902\t58\n",
            "1078105\t373\n",
            "1078502\t479\n",
            "1079206\t1838\n",
            "1080003\t2254\n",
            "1082106\t8076\n",
            "1084907\t878\n",
            "1086803\t523\n",
            "1087402\t270\n",
            "1091802\t53\n",
            "1092603\t62\n",
            "1098002\t574\n",
            "1099005\t253\n",
            "1099402\t2053\n",
            "1100303\t646\n",
            "1101303\t62\n",
            "1102705\t18\n",
            "1104205\t3415\n",
            "1104903\t93\n",
            "1105703\t17400\n",
            "1106606\t3461\n",
            "1106703\t124\n",
            "1107603\t62\n",
            "1110902\t972\n",
            "1111106\t147\n",
            "1112205\t31\n",
            "1114008\t336\n",
            "1114608\t274\n",
            "1115005\t88\n",
            "1119302\t3558\n",
            "1120302\t62\n",
            "1123302\t57\n",
            "1125203\t258\n",
            "1125904\t6272\n",
            "1126702\t656\n",
            "1127805\t11970\n",
            "1128302\t53\n",
            "1128802\t84\n",
            "1129202\t24976\n",
            "1129806\t25567\n",
            "1130802\t62\n",
            "1131504\t57\n",
            "1133705\t150\n",
            "1141307\t279\n",
            "1142308\t1330\n",
            "1143302\t10760\n",
            "1144705\t58\n",
            "1148102\t709\n",
            "1150305\t647\n",
            "1152505\t31\n",
            "1153706\t89\n",
            "1154005\t1322\n",
            "1158702\t53\n",
            "1160302\t631\n",
            "1161206\t159\n",
            "1161802\t10697\n",
            "1162403\t856\n",
            "1163003\t305\n",
            "1163703\t556\n",
            "1163807\t955\n",
            "1164102\t93\n",
            "1164802\t246\n",
            "1169502\t134\n",
            "1169706\t9235\n",
            "1172105\t249\n",
            "1172502\t53\n",
            "1177502\t605\n",
            "1177803\t93\n",
            "1182304\t365\n",
            "1186503\t62\n",
            "1186703\t62\n",
            "1188402\t1417\n",
            "1189802\t118\n",
            "1190502\t62\n",
            "1192102\t298\n",
            "1195302\t212\n",
            "1197302\t282\n",
            "1197705\t392\n",
            "1198002\t80\n",
            "1198202\t124\n",
            "1198603\t1685\n",
            "1199502\t968\n",
            "1199603\t1270\n",
            "1200305\t230\n",
            "1200704\t62\n",
            "1201206\t98\n",
            "1201602\t62\n",
            "1209402\t440\n",
            "1211902\t18\n",
            "1212402\t94\n",
            "1212903\t54\n",
            "1215605\t137\n",
            "1217305\t5264\n",
            "1219103\t4935\n",
            "1219702\t1089\n",
            "1220605\t353\n",
            "1221702\t773\n",
            "1222305\t18\n",
            "1225502\t62\n",
            "1226402\t4277\n",
            "1226505\t54\n",
            "1226603\t9557\n",
            "1227805\t768\n",
            "1228002\t215\n",
            "1232305\t500\n",
            "1233502\t62\n",
            "1233904\t4253\n",
            "1234305\t54\n",
            "1239103\t468\n",
            "1239703\t62\n",
            "1240203\t574\n",
            "1244102\t535\n",
            "1244807\t556\n",
            "1245102\t2638\n",
            "1247805\t10153\n",
            "1251103\t54\n",
            "1251902\t58\n",
            "1252306\t341\n",
            "1254404\t63\n",
            "1255905\t62\n",
            "1275804\t1382\n",
            "1281902\t186\n",
            "1288403\t114\n",
            "1288802\t53\n",
            "1288904\t16062\n",
            "1289102\t93\n",
            "1289208\t15916\n",
            "1289607\t543\n",
            "1289806\t31\n",
            "1289902\t54\n",
            "1290205\t53\n",
            "1291503\t89\n",
            "1291703\t84\n",
            "1294503\t779\n",
            "1295106\t333\n",
            "1295304\t13366\n",
            "1295407\t1502\n",
            "1298202\t1340\n",
            "1299206\t981\n",
            "1302902\t43\n",
            "1306106\t130\n",
            "1312702\t92\n",
            "1315805\t720\n",
            "1318403\t172\n",
            "1319801\t4165\n",
            "1320402\t15650\n",
            "1321105\t53\n",
            "1323002\t394\n",
            "1323202\t6684\n",
            "1324102\t53\n",
            "1324402\t1820\n",
            "1325603\t291\n",
            "1326404\t360\n",
            "1327702\t207\n",
            "1329003\t62\n",
            "1329605\t414\n",
            "1330303\t10533\n",
            "1334207\t2604\n",
            "1336004\t252\n",
            "1336707\t364\n",
            "1337703\t155\n",
            "1342202\t212\n",
            "1343302\t190\n",
            "1345904\t62\n",
            "1347605\t300\n",
            "1348502\t953\n",
            "1348603\t247\n",
            "1348702\t10253\n",
            "1349505\t4501\n",
            "1350202\t389\n",
            "1357702\t1068\n",
            "1379502\t93\n",
            "1379610\t3514\n",
            "1383002\t2300\n",
            "1385103\t1778\n",
            "1387102\t2004\n",
            "1387306\t32\n",
            "1389101\t2022\n",
            "1393008\t22288\n",
            "1393102\t1616\n",
            "1393305\t150\n",
            "1396403\t18\n",
            "1397005\t31\n",
            "1400403\t142\n",
            "1402501\t42\n",
            "1402702\t3141\n",
            "1405702\t4671\n",
            "1408203\t765\n",
            "1410005\t7470\n",
            "1410702\t17375\n",
            "1410803\t318\n",
            "1410902\t53\n",
            "1411206\t782\n",
            "1411302\t62\n",
            "1412202\t3614\n",
            "1415002\t54\n",
            "1419306\t1137\n",
            "1422208\t8\n",
            "1423706\t62\n",
            "1425203\t392\n",
            "1425404\t113\n",
            "1425605\t62\n",
            "1425902\t29\n",
            "1426204\t1725\n",
            "1430706\t1086\n",
            "1431402\t177\n",
            "1432105\t601\n",
            "1445702\t325\n",
            "1448703\t109\n",
            "1448903\t521\n",
            "1449202\t4830\n",
            "1451202\t89\n",
            "1452002\t62\n",
            "1452401\t1451\n",
            "1453403\t40\n",
            "1454303\t40\n",
            "1457002\t1692\n",
            "1457406\t224\n",
            "1457607\t935\n",
            "1458805\t62\n",
            "1463303\t155\n",
            "1463502\t4526\n",
            "1467402\t124\n",
            "1467903\t7577\n",
            "1468305\t3425\n",
            "1468502\t1580\n",
            "1468902\t557\n",
            "1469608\t541\n",
            "1469802\t382\n",
            "1470904\t47\n",
            "1471105\t63\n",
            "1471604\t49\n",
            "1473004\t2025\n",
            "1474703\t12627\n",
            "1476107\t917\n",
            "1477104\t10894\n",
            "1478302\t629\n",
            "1479405\t224\n",
            "1481202\t62\n",
            "1481403\t327\n",
            "1482805\t93\n",
            "1483106\t3943\n",
            "1484202\t93\n",
            "1484306\t3031\n",
            "1486903\t9721\n",
            "1487706\t62\n",
            "1489302\t4248\n",
            "1490505\t9\n",
            "1490803\t3790\n",
            "1495203\t14\n",
            "1495503\t31\n",
            "1496002\t62\n",
            "1498603\t1916\n",
            "1500803\t27\n",
            "1501606\t5451\n",
            "1502305\t280\n",
            "1502403\t615\n",
            "1502704\t153\n",
            "1504102\t232\n",
            "1504805\t62\n",
            "1507003\t36\n",
            "1507402\t62\n",
            "1509602\t1190\n",
            "1524906\t530\n",
            "1529503\t59\n",
            "1530402\t8040\n",
            "1532305\t168\n",
            "1535602\t223\n",
            "1537002\t1304\n",
            "1537604\t1727\n",
            "1538005\t226\n",
            "1538902\t62\n",
            "1540103\t62\n",
            "1541106\t93\n",
            "1541206\t1184\n",
            "1556903\t53\n",
            "1560702\t62\n",
            "1562404\t810\n",
            "1584102\t62\n",
            "1591905\t1040\n",
            "1599102\t62\n",
            "1621802\t134\n",
            "1686902\t150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea el directorio /data/Resultados, incluyendo cualquier directorio intermedio necesario.\n",
        "!mkdir -p /data/Resultados"
      ],
      "metadata": {
        "id": "f7M8IY9zej8p"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados en tabla, respectivamente \"total_flights_day_month.csv\"."
      ],
      "metadata": {
        "id": "kKe4XItPlQoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import pandas as pd\n",
        "\n",
        "def main():\n",
        "    \"\"\"Lee el archivo de resultados y guarda el CSV con encabezados en la carpeta de resultados.\"\"\"\n",
        "    # Leer el archivo de resultados sin encabezados\n",
        "    df = pd.read_csv('/data/total_flights_day_month/part-00000', header=None,\n",
        "                     names=['Day', 'TotalFlights'])\n",
        "\n",
        "    # Guardar el archivo CSV con encabezados en la carpeta \"data/Resultados\"\n",
        "    df.to_csv('/data/Resultados/total_flights_day_month.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "pMHsckkVgFln"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados en tabla, respectivamente \"total_flights_airport_id.csv\"."
      ],
      "metadata": {
        "id": "iSCxCawlldjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import pandas as pd\n",
        "\n",
        "def main():\n",
        "    \"\"\"Lee el archivo de resultados sin encabezados y guarda el CSV con encabezados en la carpeta de resultados.\"\"\"\n",
        "    # Leer el archivo de resultados sin encabezados\n",
        "    df = pd.read_csv('/data/total_flights_airport_id/part-00000', header=None,\n",
        "                     names=['OriginAirportID', 'TotalFlights'])\n",
        "\n",
        "    # Guardar el archivo CSV con encabezados en la carpeta \"data/Resultados\"\n",
        "    df.to_csv('/data/Resultados/total_flights_airport_id.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "fC3JmGckgHvX"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}